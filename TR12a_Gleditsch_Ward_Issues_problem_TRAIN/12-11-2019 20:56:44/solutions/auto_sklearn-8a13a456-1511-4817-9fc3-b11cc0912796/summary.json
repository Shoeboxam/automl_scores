{"model": "AutoSklearnClassifier", "description": "AutoSklearnClassifier(delete_output_folder_after_terminate=True,\n           delete_tmp_folder_after_terminate=True,\n           disable_evaluator_output=False, ensemble_memory_limit=1024,\n           ensemble_nbest=50, ensemble_size=50, exclude_estimators=None,\n           exclude_preprocessors=None, get_smac_object_callback=None,\n           include_estimators=None, include_preprocessors=None,\n           initial_configurations_via_metalearning=25, logging_config=None,\n           metadata_directory=None, ml_memory_limit=3072, n_jobs=None,\n           output_folder=None, per_run_time_limit=360,\n           resampling_strategy='cv',\n           resampling_strategy_arguments={'shuffle': False, 'folds': 10},\n           seed=1, shared_mode=False, smac_scenario_args=None,\n           time_left_for_this_task=600, tmp_folder=None)", "model_id": "8a13a456-1511-4817-9fc3-b11cc0912796", "search_id": "95c2ae0a-d714-42d6-b290-d46922f830e2", "system": "auto_sklearn", "scores": [{"value": 0.5, "metric": {"metric": "ROC_AUC"}, "target": "mido"}, {"value": 0.9922985289636258, "metric": {"metric": "ACCURACY"}, "target": "mido"}, {"value": 0, "metric": {"metric": "PRECISION"}, "target": "mido"}, {"value": 0, "metric": {"metric": "RECALL"}, "target": "mido"}, {"value": 0, "metric": {"metric": "F1"}, "target": "mido"}], "produce": [{"input": {"name": "all", "resource_uri": "file:///ravens_volume/test_data/TR12a_Gleditsch_Ward_Issues/TRAIN/dataset_TRAIN/tables/learningData.csv"}, "configuration": {"predict_type": "RAW"}, "data_pointer": "/ravens_volume/solvers/produce/c1d0354f-5815-4750-801d-2c03f57a510b.csv"}, {"input": {"name": "all", "resource_uri": "file:///ravens_volume/test_data/TR12a_Gleditsch_Ward_Issues/TRAIN/dataset_TRAIN/tables/learningData.csv"}, "configuration": {"predict_type": "PROBABILITIES"}, "data_pointer": "/ravens_volume/solvers/produce/05c9ea68-2c13-4512-ad28-a75ca7392787.csv"}, {"input": {"name": "test", "resource_uri": "file:///ravens_volume/test_output/TR12a_Gleditsch_Ward_Issues/additional_inputs/test/ws_516/2019-11-12_19-51-53/tables/learningData.csv"}, "configuration": {"predict_type": "RAW"}, "data_pointer": "/ravens_volume/solvers/produce/1fada29a-9e5f-415f-88cd-87f109dcbd47.csv"}, {"input": {"name": "test", "resource_uri": "file:///ravens_volume/test_output/TR12a_Gleditsch_Ward_Issues/additional_inputs/test/ws_516/2019-11-12_19-51-53/tables/learningData.csv"}, "configuration": {"predict_type": "PROBABILITIES"}, "data_pointer": "/ravens_volume/solvers/produce/69610d35-6a8f-4c4d-9975-b22912140155.csv"}, {"input": {"name": "train", "resource_uri": "file:///ravens_volume/test_output/TR12a_Gleditsch_Ward_Issues/additional_inputs/train/ws_516/2019-11-12_19-51-53/tables/learningData.csv"}, "configuration": {"predict_type": "RAW"}, "data_pointer": "/ravens_volume/solvers/produce/2e445563-3952-4411-9ea8-c5253649629f.csv"}, {"input": {"name": "train", "resource_uri": "file:///ravens_volume/test_output/TR12a_Gleditsch_Ward_Issues/additional_inputs/train/ws_516/2019-11-12_19-51-53/tables/learningData.csv"}, "configuration": {"predict_type": "PROBABILITIES"}, "data_pointer": "/ravens_volume/solvers/produce/80e0d706-80ff-4c83-8552-9dcb7cad6405.csv"}, {"input": {"name": "partials", "resource_uri": "file:///ravens_volume/test_output/TR12a_Gleditsch_Ward_Issues/additional_inputs/partials/ws_516/2019-11-12_19-51-52/tables/learningData.csv"}, "configuration": {"predict_type": "RAW"}, "data_pointer": "/ravens_volume/solvers/produce/c53f22c5-41d7-4b80-a316-0bbadaf70e36.csv"}, {"input": {"name": "partials", "resource_uri": "file:///ravens_volume/test_output/TR12a_Gleditsch_Ward_Issues/additional_inputs/partials/ws_516/2019-11-12_19-51-52/tables/learningData.csv"}, "configuration": {"predict_type": "PROBABILITIES"}, "data_pointer": "/ravens_volume/solvers/produce/5b9fa803-4d4d-4301-9886-52e376d81046.csv"}]}