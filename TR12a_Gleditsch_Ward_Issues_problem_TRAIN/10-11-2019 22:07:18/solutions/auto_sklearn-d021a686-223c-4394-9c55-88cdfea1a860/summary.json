{"model": "AutoSklearnClassifier", "description": "AutoSklearnClassifier(delete_output_folder_after_terminate=True,\n           delete_tmp_folder_after_terminate=True,\n           disable_evaluator_output=False, ensemble_memory_limit=1024,\n           ensemble_nbest=50, ensemble_size=50, exclude_estimators=None,\n           exclude_preprocessors=None, get_smac_object_callback=None,\n           include_estimators=None, include_preprocessors=None,\n           initial_configurations_via_metalearning=25, logging_config=None,\n           metadata_directory=None, ml_memory_limit=3072, n_jobs=None,\n           output_folder=None, per_run_time_limit=360,\n           resampling_strategy='cv',\n           resampling_strategy_arguments={'shuffle': False, 'folds': 10},\n           seed=1, shared_mode=False, smac_scenario_args=None,\n           time_left_for_this_task=30, tmp_folder=None)", "model_id": "d021a686-223c-4394-9c55-88cdfea1a860", "search_id": "f11ee7be-78d2-4120-b808-dc22a147b497", "system": "auto_sklearn", "scores": [{"value": 0.5, "metric": {"metric": "ROC_AUC"}, "target": "mido"}, {"value": 0.9901852261825695, "metric": {"metric": "ACCURACY"}, "target": "mido"}, {"value": 0, "metric": {"metric": "PRECISION"}, "target": "mido"}, {"value": 0, "metric": {"metric": "RECALL"}, "target": "mido"}, {"value": 0, "metric": {"metric": "F1"}, "target": "mido"}], "produce": [{"input": {"name": "all", "resource_uri": "file:///ravens_volume/test_data/TR12a_Gleditsch_Ward_Issues/TRAIN/dataset_TRAIN/tables/learningData.csv"}, "configuration": {"predict_type": "RAW"}, "data_pointer": "/ravens_volume/solvers/produce/f6e3204a-f8f9-4990-b8bd-78d16acf6ee9.csv"}, {"input": {"name": "all", "resource_uri": "file:///ravens_volume/test_data/TR12a_Gleditsch_Ward_Issues/TRAIN/dataset_TRAIN/tables/learningData.csv"}, "configuration": {"predict_type": "PROBABILITIES"}, "data_pointer": "/ravens_volume/solvers/produce/fa1c994b-bc47-4514-89df-2dbcd61575d1.csv"}, {"input": {"name": "test", "resource_uri": "file:///ravens_volume/test_output/TR12a_Gleditsch_Ward_Issues/additional_inputs/test/ws_502/2019-11-10_21-24-58/tables/learningData.csv"}, "configuration": {"predict_type": "RAW"}, "data_pointer": "/ravens_volume/solvers/produce/974449fb-641b-484e-ad18-862a542f995a.csv"}, {"input": {"name": "test", "resource_uri": "file:///ravens_volume/test_output/TR12a_Gleditsch_Ward_Issues/additional_inputs/test/ws_502/2019-11-10_21-24-58/tables/learningData.csv"}, "configuration": {"predict_type": "PROBABILITIES"}, "data_pointer": "/ravens_volume/solvers/produce/d4af92fe-faa4-4c91-b4bb-80df16981e1b.csv"}, {"input": {"name": "train", "resource_uri": "file:///ravens_volume/test_output/TR12a_Gleditsch_Ward_Issues/additional_inputs/train/ws_502/2019-11-10_21-24-57/tables/learningData.csv"}, "configuration": {"predict_type": "RAW"}, "data_pointer": "/ravens_volume/solvers/produce/7c5e25dc-9c68-4209-8701-8a20e5fb5158.csv"}, {"input": {"name": "train", "resource_uri": "file:///ravens_volume/test_output/TR12a_Gleditsch_Ward_Issues/additional_inputs/train/ws_502/2019-11-10_21-24-57/tables/learningData.csv"}, "configuration": {"predict_type": "PROBABILITIES"}, "data_pointer": "/ravens_volume/solvers/produce/6403a3dd-c99d-4bd8-9590-ca52c2c3b4af.csv"}, {"input": {"name": "partials", "resource_uri": "file:///ravens_volume/test_output/TR12a_Gleditsch_Ward_Issues/additional_inputs/partials/ws_502/2019-11-10_21-24-56/tables/learningData.csv"}, "configuration": {"predict_type": "RAW"}, "data_pointer": "/ravens_volume/solvers/produce/04bc48e8-f47f-49e1-9244-861831423d56.csv"}, {"input": {"name": "partials", "resource_uri": "file:///ravens_volume/test_output/TR12a_Gleditsch_Ward_Issues/additional_inputs/partials/ws_502/2019-11-10_21-24-56/tables/learningData.csv"}, "configuration": {"predict_type": "PROBABILITIES"}, "data_pointer": "/ravens_volume/solvers/produce/bc84ba10-5bd8-4b6a-848e-fdecfbda5feb.csv"}]}