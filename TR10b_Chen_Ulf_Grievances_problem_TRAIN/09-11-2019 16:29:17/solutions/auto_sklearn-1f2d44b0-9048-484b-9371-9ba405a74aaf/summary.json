{"model": "AutoSklearnClassifier", "description": "AutoSklearnClassifier(delete_output_folder_after_terminate=True,\n           delete_tmp_folder_after_terminate=True,\n           disable_evaluator_output=False, ensemble_memory_limit=1024,\n           ensemble_nbest=50, ensemble_size=50, exclude_estimators=None,\n           exclude_preprocessors=None, get_smac_object_callback=None,\n           include_estimators=None, include_preprocessors=None,\n           initial_configurations_via_metalearning=25, logging_config=None,\n           metadata_directory=None, ml_memory_limit=3072, n_jobs=None,\n           output_folder=None, per_run_time_limit=360,\n           resampling_strategy='holdout',\n           resampling_strategy_arguments={'shuffle': False, 'train_size': 0.35},\n           seed=1, shared_mode=False, smac_scenario_args=None,\n           time_left_for_this_task=3600, tmp_folder=None)", "model_id": "1f2d44b0-9048-484b-9371-9ba405a74aaf", "search_id": "8e18e9bd-c4fe-4c7f-873a-f6f105974c60", "system": "auto_sklearn", "scores": [{"value": 0.49870466321243523, "metric": {"metric": "ROC_AUC"}, "target": "nvc.start.1"}, {"value": 0.9722222222222222, "metric": {"metric": "ACCURACY"}, "target": "nvc.start.1"}, {"value": 0, "metric": {"metric": "PRECISION"}, "target": "nvc.start.1"}, {"value": 0, "metric": {"metric": "RECALL"}, "target": "nvc.start.1"}, {"value": 0, "metric": {"metric": "F1"}, "target": "nvc.start.1"}], "produce": [{"input": {"name": "test", "resource_uri": "file:///ravens_volume/test_output/TR10b_Chen_Ulf_Grievances/additional_inputs/test/ws_486/2019-11-09_10-41-47/tables/learningData.csv"}, "configuration": {"predict_type": "RAW"}, "data_pointer": "/ravens_volume/solvers/produce/29e01934-03ba-460c-bf89-cb64255477d8.csv"}, {"input": {"name": "train", "resource_uri": "file:///ravens_volume/test_output/TR10b_Chen_Ulf_Grievances/additional_inputs/train/ws_486/2019-11-09_10-41-47/tables/learningData.csv"}, "configuration": {"predict_type": "RAW"}, "data_pointer": "/ravens_volume/solvers/produce/a5e71b07-032a-4963-a1e4-c881457598b6.csv"}, {"input": {"name": "partials", "resource_uri": "file:///ravens_volume/test_output/TR10b_Chen_Ulf_Grievances/additional_inputs/partials/ws_486/2019-11-09_10-41-47/tables/learningData.csv"}, "configuration": {"predict_type": "RAW"}, "data_pointer": "/ravens_volume/solvers/produce/cc1ae2c4-510c-42f5-bc9c-8088050ecae0.csv"}, {"input": {"name": "test", "resource_uri": "file:///ravens_volume/test_output/TR10b_Chen_Ulf_Grievances/additional_inputs/test/ws_486/2019-11-09_10-41-47/tables/learningData.csv"}, "configuration": {"predict_type": "PROBABILITIES"}, "data_pointer": "/ravens_volume/solvers/produce/a1c78544-9afb-48ea-8ad2-76abf1abc28d.csv"}, {"input": {"name": "train", "resource_uri": "file:///ravens_volume/test_output/TR10b_Chen_Ulf_Grievances/additional_inputs/train/ws_486/2019-11-09_10-41-47/tables/learningData.csv"}, "configuration": {"predict_type": "PROBABILITIES"}, "data_pointer": "/ravens_volume/solvers/produce/2a7dc462-ba81-4707-8602-0b7e9091a803.csv"}, {"input": {"name": "partials", "resource_uri": "file:///ravens_volume/test_output/TR10b_Chen_Ulf_Grievances/additional_inputs/partials/ws_486/2019-11-09_10-41-47/tables/learningData.csv"}, "configuration": {"predict_type": "PROBABILITIES"}, "data_pointer": "/ravens_volume/solvers/produce/9e01016e-196a-486e-80ae-feac092892ae.csv"}]}